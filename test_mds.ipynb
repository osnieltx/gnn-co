{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "from copy import deepcopy\n",
    "from random import randint, choice\n",
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from graph import create_graph, milp_solve, milp_solve_mds, mdsi, clustering_coefficient, \\\n",
    "    jaccard_coefficient\n",
    "from pyg import geom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "figsize = (15, 6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ckp_path = './experiments/2024-11-06-1120/version_0/checkpoints/epoch=99-step=99.ckpt'\n",
    "checkpoint = torch.load(ckp_path, map_location=torch.device('cpu'))\n",
    "hyper_parameters = checkpoint['hyper_parameters']\n",
    "\n",
    "use_clustering_coefficient = False\n",
    "use_jaccard_coefficient = False\n",
    "\n",
    "solver = milp_solve_mds\n",
    "indexer = mdsi\n",
    "\n",
    "dataset = None\n",
    "train_test_index = None\n",
    "\n",
    "n, p = 10, .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "graphs: List[geom_data.Data] = []\n",
    "if dataset:\n",
    "    if isinstance(train_test_index, int):\n",
    "        test_index = range(train_test_index)\n",
    "    else:\n",
    "        _, test_index = torch.load(f'{train_test_index}/0_train_test_idx.pt')\n",
    "    graphs = [torch.load(f'{dataset}/{i}.pt') for i in tqdm(test_index, unit='graph')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c_in'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 11\u001B[0m\n\u001B[1;32m      4\u001B[0m state_dict\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss_module.pos_weight\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# k = k.replace('.weight', '.lin.weight').replace('model.', '')\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# if 'output_layers' in k:\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#     v = v.T\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# if k == 'layers.0.lin.weight':\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#     v = v.T\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m gnn \u001B[38;5;241m=\u001B[39m GNNModel(c_in\u001B[38;5;241m=\u001B[39m\u001B[43mhyper_parameters\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mc_in\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m, c_hidden\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m, c_out\u001B[38;5;241m=\u001B[39mhyper_parameters[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc_out\u001B[39m\u001B[38;5;124m'\u001B[39m], num_layers\u001B[38;5;241m=\u001B[39mhyper_parameters[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_layers\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     12\u001B[0m                m\u001B[38;5;241m=\u001B[39mhyper_parameters[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;124m'\u001B[39m], dp_rate\u001B[38;5;241m=\u001B[39mhyper_parameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdp_rate\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     13\u001B[0m gnn\u001B[38;5;241m.\u001B[39mload_state_dict(state_dict)\n\u001B[1;32m     14\u001B[0m gnn\u001B[38;5;241m.\u001B[39meval()\n",
      "\u001B[0;31mKeyError\u001B[0m: 'c_in'"
     ]
    }
   ],
   "source": [
    "from models import GNNModel\n",
    "\n",
    "state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "state_dict.pop('loss_module.pos_weight', None)\n",
    "# k = k.replace('.weight', '.lin.weight').replace('model.', '')\n",
    "# if 'output_layers' in k:\n",
    "#     v = v.T\n",
    "# if k == 'layers.0.lin.weight':\n",
    "#     v = v.T\n",
    "\n",
    "gnn = GNNModel(c_in=hyper_parameters['c_in'], c_hidden=30, c_out=hyper_parameters['c_out'], num_layers=hyper_parameters['num_layers'],\n",
    "               m=hyper_parameters['m'], dp_rate=hyper_parameters.get('dp_rate'))\n",
    "gnn.load_state_dict(state_dict)\n",
    "gnn.eval()\n",
    "gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_x(g, n):\n",
    "    idx_t = torch.Tensor([[i] for i in range(n)])\n",
    "    x = clustering_coefficient(g)[:, 1].unsqueeze(1) if use_clustering_coefficient else torch.Tensor([[1.]]*n)\n",
    "    if use_jaccard_coefficient:\n",
    "        jc = jaccard_coefficient(g, n, 8)\n",
    "        x = torch.cat((x, jc), 1)\n",
    "    return torch.cat([idx_t, x], dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if graphs:\n",
    "    tg = choice(graphs)\n",
    "    g = tg.edge_index\n",
    "else:\n",
    "    g = create_graph(n, p)\n",
    "    # g = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 4]])\n",
    "\n",
    "edge_list = [(int(a), int(b)) for a, b in g.T]\n",
    "g_n = nx.from_edgelist(edge_list)\n",
    "x = get_x(g, n)\n",
    "g_n.x = x\n",
    "g_n.edge_list = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(g_n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward(gnn, g: nx.Graph):\n",
    "    \"\"\"\n",
    "    return\n",
    "     - prob_maps: lists of sorted vertices by prob\n",
    "     - maps: truncated maps\n",
    "     - id_better_solution\n",
    "    \"\"\"\n",
    "    prob_maps = gnn.forward(g.x[:, 1:], g.edge_list)\n",
    "    prob_maps = torch.sigmoid(prob_maps)\n",
    "    maps = (prob_maps > .5).float()\n",
    "\n",
    "    _, _, best_sol_id = mdsi(maps, g.edge_list)\n",
    "\n",
    "    prob_maps = prob_maps.squeeze(2).tolist()\n",
    "    sorted_prob_maps = []\n",
    "    for pb_m in prob_maps:\n",
    "        prob = list(enumerate(pb_m))\n",
    "        prob.sort(key=lambda x: x[1], reverse=True)\n",
    "        sorted_prob_maps.append(prob)\n",
    "\n",
    "    return sorted_prob_maps, maps, best_sol_id\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if graphs:\n",
    "    y = tg.y\n",
    "    sol = {i for i, s in enumerate(y) if s}\n",
    "else:\n",
    "    sol = solver(g, n)\n",
    "    y = torch.FloatTensor([[n in sol] for n in range(n)])\n",
    "\n",
    "print(f'{sol=}')\n",
    "sorted_prob_maps, maps, id_best_sol = forward(gnn, g_n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = ((maps == y).sum(dim=1) / y.size(dim=0)).max().item()\n",
    "aon = (maps == y).all(dim=1).sum().float().item()\n",
    "\n",
    "cov_size, uncovered_nodes, idx = indexer(maps, g)\n",
    "\n",
    "print(f'{acc=:.2f}\\n{aon=}\\n{cov_size[idx]=} \\n{uncovered_nodes[idx]=}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mds_greedy(gnn: GNNModel, g: nx.Graph, verbose=False) -> set:\n",
    "    v = verbose\n",
    "    g_ = deepcopy(g)\n",
    "    sorted_prob_maps, _, id_best_sol = forward(gnn, g_)\n",
    "    s = set()\n",
    "    while g_:\n",
    "        n_s = set()\n",
    "        for v, _ in sorted_prob_maps[id_best_sol]:\n",
    "            if verbose: print(f'{len(s)=}, {g=}')\n",
    "            if v in s | n_s or v not in g_:\n",
    "                continue\n",
    "\n",
    "            s.add(v)\n",
    "            if verbose: print(v, end=' ')\n",
    "            for u in list(g_[v]):\n",
    "                n_s.add(u)\n",
    "                # preventing lonely node after v removed\n",
    "                if len(g_[u]) == 1:\n",
    "                    g_.remove_node(u)\n",
    "\n",
    "            g_.remove_node(v)\n",
    "        if set(g_) <= n_s | s:\n",
    "            break\n",
    "    return s\n",
    "\n",
    "s = mds_greedy(gnn, g_n)\n",
    "s, len(s) == len(sol), all(v in s or len(g_n[v].keys() & s) > 0 for v in g_n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(g_n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "\n",
    "try:\n",
    "    layout = nx.planar_layout(g_n)\n",
    "except:\n",
    "    layout = nx.drawing.random_layout(g_n)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(18, 8))\n",
    "\n",
    "node_colors = ['blue' if n in sol else 'gray' for n in g_n]\n",
    "edge_color = (0.8, 0.8, 0.8)\n",
    "nx.draw(g_n, with_labels=True, node_color=node_colors, edge_color=edge_color, pos=layout, ax=axes[0])\n",
    "\n",
    "mvc_color = ['blue' if v else 'gray' for v in maps[id_best_sol].squeeze()]\n",
    "node_colors = [mvc_color[n] for n in g_n]\n",
    "label_dict = {n: f'{v*100:.0f}%' for n, v in sorted_prob_maps[id_best_sol]}\n",
    "nx.draw(g_n, with_labels=True, node_color=node_colors, edge_color=edge_color, pos=layout, ax=axes[1], labels=label_dict)\n",
    "\n",
    "mvc_color = ['blue' if v in s else 'gray' for v in range(n)]\n",
    "node_colors = [mvc_color[n] for n in g_n]\n",
    "nx.draw(g_n, with_labels=True, node_color=node_colors, edge_color=edge_color, pos=layout, ax=axes[2])\n",
    "\n",
    "for i, t in enumerate(['MILP', 'GNN + truncate', 'GNN + greedy']):\n",
    "    axes[i].set_title(t)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# raise KeyError"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DS score output distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tt_g = 100\n",
    "l = torch.nn.BCEWithLogitsLoss()\n",
    "m = hyper_parameters['m']\n",
    "\n",
    "results = [0] * m\n",
    "gnn_ref_ltq_mvc = [False] * tt_g\n",
    "gnn_ref_cv = [False] * tt_g  # if the solution is a vertex cover\n",
    "cov_size_by_head = [0] * m\n",
    "uncovered_nodes_by_head = [0] * m\n",
    "indexes = set(range(len(graphs)))\n",
    "\n",
    "for i in trange(tt_g):\n",
    "    if graphs:\n",
    "        tg = graphs[indexes.pop()]\n",
    "        g = tg.edge_index\n",
    "        mds = {i for i, s in enumerate(tg.y) if s}\n",
    "    else:\n",
    "        g = create_graph(n, p)\n",
    "        mds = solver(g, n)\n",
    "\n",
    "    x = get_x(g, n)\n",
    "    g_n = nx.from_edgelist(g.T.tolist())\n",
    "    g_n.x = x\n",
    "    g_n.edge_list = g\n",
    "\n",
    "    _, maps, idx = forward(gnn, g_n) # useful?\n",
    "\n",
    "    cov_size, uncovered_nodes, idx = mdsi(maps, g)\n",
    "    mds_index = cov_size + uncovered_nodes\n",
    "\n",
    "    for j, m_i in enumerate(mds_index):\n",
    "        if m_i <= mds_index[idx]:\n",
    "            results[j] += 1\n",
    "\n",
    "    s = mds_greedy(gnn, g_n)\n",
    "    gnn_ref_ltq_mvc[i] = len(s) <= len(mds)\n",
    "    gnn_ref_cv[i] = all(v in s or len(g_n[v].keys() & s) > 0 for v in g_n)\n",
    "\n",
    "    cov_size, uncovered_nodes, _ = mdsi(maps, g)\n",
    "    for head in range(m):\n",
    "        cov_size_by_head[head] += cov_size[head].item()\n",
    "        uncovered_nodes_by_head[head] += uncovered_nodes[head].item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.clear()\n",
    "ax = pd.DataFrame({\n",
    "    'avg DS size': [s/tt_g for s in cov_size_by_head],\n",
    "    'avg unc nodes': [s/tt_g for s in uncovered_nodes_by_head]\n",
    "}).plot.bar(figsize=figsize, stacked=True)\n",
    "ax.yaxis.grid(True, which='major', linewidth=.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.clear()\n",
    "ax = pd.DataFrame({\n",
    "    '# output with MIN DSS': [r for r in results],\n",
    "}).plot.bar(figsize=figsize)\n",
    "ax.bar_label(ax.containers[0], labels=results, padding=3, size='small')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum(gnn_ref_ltq_mvc)/tt_g, sum(gnn_ref_cv)/tt_g"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# raise Exception"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Recursive MDS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tensor_pop(t, ids):\n",
    "    if not isinstance(ids, Iterable):\n",
    "        ids = [ids]\n",
    "\n",
    "    index = t[:,0]\n",
    "    mask = torch.tensor([i in ids for i in index])\n",
    "    t[mask, 1:] = 0\n",
    "\n",
    "    return t\n",
    "\n",
    "def ei_remove_node(edge_index, node):\n",
    "    mask = (edge_index[0] != node) & (edge_index[1] != node)\n",
    "    new_edge_index = edge_index[:, mask]\n",
    "    return new_edge_index\n",
    "\n",
    "def remove_node(g: nx.Graph, n: int):\n",
    "    g.remove_node(n)\n",
    "    g.x = tensor_pop(g.x, n)\n",
    "    g.edge_list = ei_remove_node(g.edge_list, n)\n",
    "    return g"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def mds_r(gnn, g: nx.Graph, verbose=False):\n",
    "    verb = verbose\n",
    "    g_ = deepcopy(g)\n",
    "    sorted_prob_maps, _, id_best_sol = forward(gnn, g_)\n",
    "    s = set()\n",
    "    n_s = set()\n",
    "\n",
    "    if verb:\n",
    "        print([(v, f'{p:.2f}') for v, p in sorted_prob_maps[id_best_sol]])\n",
    "        print(g_.nodes,'\\n', g.edge_list, f'\\n{g.x=}')\n",
    "\n",
    "    for v, p in sorted_prob_maps[id_best_sol]:\n",
    "        if v in s | n_s:\n",
    "            break\n",
    "        if v not in g_:\n",
    "            # this can happen in a recursive call because the input x is not resized\n",
    "            # to avoid problems with the vector indices on the edge_index,\n",
    "            # given that it keep vertex with index > len(x) if x was decreased.\n",
    "            # it could be faster to remove the indices from X and ajust the edge_index\n",
    "            # to avoid passing unecessary nodes to the network\n",
    "            continue\n",
    "\n",
    "        s.add(v)\n",
    "        if verb: print(v, end=' ')\n",
    "        for u in list(g_[v]):\n",
    "            n_s.add(u)\n",
    "\n",
    "        for u in list(g_[v]):\n",
    "            # preventing lonely node after v removed\n",
    "            # if len(g_[u]) == 1:\n",
    "            #     g_ = remove_node(g_, u)\n",
    "            if not g_[u].keys() - (s | n_s):\n",
    "                g_ = remove_node(g_, u)\n",
    "\n",
    "        g_ = remove_node(g_, v)\n",
    "\n",
    "        if set(g_) <= n_s | s:\n",
    "            break\n",
    "\n",
    "    if not(set(g_) <= n_s | s):\n",
    "        if verb: print('rec')\n",
    "        for n, p in sorted_prob_maps[id_best_sol]:\n",
    "            g_.x[n, 1] = p*10\n",
    "        for n in list(g_):\n",
    "            if not g_[n]:\n",
    "                g_ = remove_node(g_, n)\n",
    "        s |= mds_r(gnn, g_, verbose=verb)\n",
    "\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if graphs:\n",
    "    tg = choice(graphs)\n",
    "    g = tg.edge_index\n",
    "    sol = {i for i, s in enumerate(tg.y) if s}\n",
    "else:\n",
    "    g = create_graph(n, p)\n",
    "    sol = solver(g, n)\n",
    "    y = torch.FloatTensor([[n in sol] for n in range(n)])\n",
    "\n",
    "x = get_x(g, n)\n",
    "g_n = nx.from_edgelist(g.T.tolist())\n",
    "g_n.x = x\n",
    "g_n.edge_list = g\n",
    "\n",
    "s = mds_r(gnn, g_n)\n",
    "\n",
    "print('\\n', sol, s)\n",
    "print(f'same size? {len(sol) == len(s)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    layout = nx.planar_layout(g_n)\n",
    "except:\n",
    "    layout = nx.drawing.spring_layout(g_n)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(18, 8))\n",
    "\n",
    "node_colors = ['blue' if n in sol else 'gray' for n in g_n]\n",
    "nx.draw(g_n, with_labels=True, node_color=node_colors, pos=layout, ax=axes[0])\n",
    "\n",
    "node_colors = ['blue' if n in s else 'gray' for n in g_n]\n",
    "nx.draw(g_n, with_labels=True, node_color=node_colors, pos=layout, ax=axes[1])\n",
    "\n",
    "for i, t in enumerate(['MILP', 'GNN + greedy + recursive']):\n",
    "    axes[i].set_title(t)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# raise Exception"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tree Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tree_search(gnn, g: nx.Graph, max_expansions=10):\n",
    "    g.s = set()\n",
    "    bag = [g]\n",
    "    best = set(g.nodes)\n",
    "\n",
    "    expansions = 0\n",
    "    found_min_at = 0\n",
    "    while expansions < max_expansions and bag:\n",
    "        g_id = randint(0, len(bag)-1)\n",
    "        g = bag.pop(g_id)\n",
    "        prob_maps, _, _ = forward(gnn, g)\n",
    "\n",
    "        for m in prob_maps:\n",
    "            s = set()\n",
    "            g_ = deepcopy(g)\n",
    "            n_s = set()\n",
    "            for v, _ in m:\n",
    "                if v not in g_:\n",
    "                    continue\n",
    "                if v in s | n_s:\n",
    "                    break\n",
    "\n",
    "                s.add(v)\n",
    "                for u in list(g_[v].keys()):\n",
    "                    n_s.add(u)\n",
    "                for u in list(g_[v]):\n",
    "                    if not g_[u].keys() - (s | n_s):\n",
    "                        g_ = remove_node(g_, u)\n",
    "\n",
    "                g_ = remove_node(g_, v)\n",
    "\n",
    "            new_mds = s | g_.s\n",
    "            if not set(g_) - (new_mds | n_s):\n",
    "                if len(new_mds) < len(best):\n",
    "                    best = new_mds\n",
    "                    found_min_at = expansions + 1\n",
    "            else:\n",
    "                g_.s = new_mds\n",
    "                # TODO update g_.x and g_.edge_list\n",
    "                bag.append(g_)\n",
    "\n",
    "        expansions += 1\n",
    "\n",
    "    return best, found_min_at"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if graphs:\n",
    "    tg = choice(graphs)\n",
    "    g = tg.edge_index\n",
    "    mds = {i for i, s in enumerate(tg.y) if s}\n",
    "else:\n",
    "    g = create_graph(n, p)\n",
    "    mds = solver(g, n)\n",
    "    y = torch.FloatTensor([[n in mds] for n in range(n)])\n",
    "\n",
    "x = get_x(g, n)\n",
    "g_n = nx.from_edgelist(g.T.tolist())\n",
    "g_n.x = x\n",
    "g_n.edge_list = g\n",
    "\n",
    "solution = tree_search(gnn, g_n)\n",
    "\n",
    "mds, solution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Methods Comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "method_by_id = {0: mds_greedy, 1: mds_r, 2: tree_search}\n",
    "# method_by_id = {2: tree_search}\n",
    "valid_ds:    List[bool] = [[], [], []]\n",
    "size_eq_mlip: List[bool] = [[], [], []]\n",
    "avg_exp_to_find_min = 0\n",
    "\n",
    "tt_g = 100\n",
    "graphs_s = []\n",
    "max_d = 0\n",
    "\n",
    "print(f'sampling {tt_g} x G{n, p}')\n",
    "indexes = set(range(len(graphs)))\n",
    "for i in trange(tt_g):\n",
    "    y = None\n",
    "    if graphs:\n",
    "        tg = graphs[indexes.pop()]\n",
    "        g = tg.edge_index\n",
    "        y = tg.y\n",
    "    else:\n",
    "        g = create_graph(n, p)\n",
    "    x = get_x(g, n)\n",
    "    g_n = nx.from_edgelist(g.T.tolist())\n",
    "    g_n.x = x\n",
    "    g_n.edge_list = g\n",
    "    g_n.y = y\n",
    "    if x[:,1].max() > max_d:\n",
    "        max_d = x[:,1].max()\n",
    "    graphs_s.append(g_n)\n",
    "\n",
    "print(f'{max_d=}')\n",
    "print(f'solving mds')\n",
    "for g_n in tqdm(graphs_s):\n",
    "    # g_n.x[:, 1] = g_n.x[:, 1]/max_d\n",
    "    if g_n.y is not None:\n",
    "        mds = {i for i, s in enumerate(g_n.y) if s}\n",
    "    else:\n",
    "        mds = solver(g_n.edge_list, n)\n",
    "\n",
    "    for m_id, func in method_by_id.items():\n",
    "        s = func(gnn, g_n)\n",
    "        if isinstance(s, tuple):\n",
    "            avg_exp_to_find_min += s[1]\n",
    "            s = s[0]\n",
    "        valid_ds[m_id].append(all(v in s or len(g_n[v].keys() & s) > 0 for v in g_n))\n",
    "        size_eq_mlip[m_id].append(len(s) <= len(mds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for m_id, func in method_by_id.items():\n",
    "    print(f'{func.__name__:<15} {100*sum(valid_ds[m_id])/tt_g}% valid DS      {100*sum(size_eq_mlip[m_id])/tt_g}% equivalent to MILP')\n",
    "\n",
    "print(f'{\" \"*16}avg expansions to find DS {avg_exp_to_find_min/tt_g:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raise Exception"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "method_by_id = {0: mds_greedy, 1: mds_r, 2: tree_search}\n",
    "valid_ds    = [[], [], []]\n",
    "size_eq_mlip = [[], [], []]\n",
    "avg_exp_to_find_min = 0\n",
    "\n",
    "tt_g = 100\n",
    "n = 200\n",
    "p = .25\n",
    "for i in trange(tt_g):\n",
    "    g = create_graph(n, p)\n",
    "    x = get_x(g, n)\n",
    "    g_n = nx.from_edgelist(g.T.tolist())\n",
    "    g_n.x = x\n",
    "    g_n.edge_list = g\n",
    "\n",
    "    mds = solver(g, n, time_limit=120)\n",
    "    y = torch.FloatTensor([[n in mds] for n in range(n)])\n",
    "\n",
    "    for m_id, func in method_by_id.items():\n",
    "        s = func(gnn, g_n)\n",
    "        if isinstance(s, tuple):\n",
    "            avg_exp_to_find_min += s[1]\n",
    "            s = s[0]\n",
    "        valid_ds[m_id].append(all(v in s or len(g_n[v].keys() & s) > 0 in s for v in g_n))\n",
    "        size_eq_mlip[m_id].append(len(s) <= len(mds))\n",
    "\n",
    "for m_id, func in method_by_id.items():\n",
    "    print(f'{func.__name__:<15} {100*sum(valid_ds[m_id])/tt_g}% valid DS      {100*sum(size_eq_mlip[m_id])/tt_g}% equivalent to MILP')\n",
    "\n",
    "print(f'{\" \"*16}avg expansions to find DS {avg_exp_to_find_min/tt_g:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from graph import prepare_graph\n",
    "from functools import partial\n",
    "\n",
    "method_by_id = {0: mds_greedy, 1: mds_r, 2: tree_search}\n",
    "# method_by_id = {2: tree_search}\n",
    "valid_ds:    List[bool] = [[], [], []]\n",
    "size_eq_mlip: List[bool] = [[], [], []]\n",
    "avg_exp_to_find_min = 0\n",
    "\n",
    "tt_g = 100\n",
    "n = 200\n",
    "p = .25\n",
    "graphs = []\n",
    "\n",
    "print(f'sampling {tt_g} x G{n, p}')\n",
    "get_graph = partial(prepare_graph, n=n, p=p, solver=solver, solver_kwargs={'time_limit': 120})\n",
    "with Pool() as p:\n",
    "    graphs = list(tqdm(\n",
    "        p.imap_unordered(get_graph, range(tt_g)),\n",
    "        total=tt_g, unit='graph'))\n",
    "\n",
    "print(f'solving mds')\n",
    "for g_n in tqdm(graphs):\n",
    "    # g_n.x[:, 1] = g_n.x[:, 1]/max_d\n",
    "    if g_n.y is not None:\n",
    "        mds = {i for i, s in enumerate(g_n.y) if s}\n",
    "    else:\n",
    "        mds = solver(g_n.edge_list, n)\n",
    "\n",
    "    for m_id, func in method_by_id.items():\n",
    "        s = func(gnn, g_n)\n",
    "        if isinstance(s, tuple):\n",
    "            avg_exp_to_find_min += s[1]\n",
    "            s = s[0]\n",
    "        valid_ds[m_id].append(all(v in s or len(g_n[v].keys() & s) > 0 for v in g_n))\n",
    "        size_eq_mlip[m_id].append(len(s) <= len(mds))\n",
    "\n",
    "for m_id, func in method_by_id.items():\n",
    "    print(f'{func.__name__:<15} {100*sum(valid_ds[m_id])/tt_g}% valid DS      {100*sum(size_eq_mlip[m_id])/tt_g}% equivalent to MILP')\n",
    "\n",
    "print(f'{\" \"*16}avg expansions to find DS {avg_exp_to_find_min/tt_g:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graphs[0].y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for g in graphs:\n",
    "    g.edge_list = g.edge_index\n",
    "    g.x = get_x(g, n)\n",
    "\n",
    "print(f'solving mds')\n",
    "for g_n in tqdm(graphs):\n",
    "    # g_n.x[:, 1] = g_n.x[:, 1]/max_d\n",
    "    if g_n.y is not None:\n",
    "        mds = {i for i, s in enumerate(g_n.y) if s}\n",
    "    else:\n",
    "        mds = solver(g_n.edge_list, n)\n",
    "\n",
    "    for m_id, func in method_by_id.items():\n",
    "        print(func.__name__)\n",
    "        s = func(gnn, g_n, verbose=True)\n",
    "        if isinstance(s, tuple):\n",
    "            avg_exp_to_find_min += s[1]\n",
    "            s = s[0]\n",
    "        valid_ds[m_id].append(all(v in s or len(g_n[v].keys() & s) > 0 for v in g_n))\n",
    "        size_eq_mlip[m_id].append(len(s) <= len(mds))\n",
    "\n",
    "for m_id, func in method_by_id.items():\n",
    "    print(f'{func.__name__:<15} {100*sum(valid_ds[m_id])/tt_g}% valid DS      {100*sum(size_eq_mlip[m_id])/tt_g}% equivalent to MILP')\n",
    "\n",
    "print(f'{\" \"*16}avg expansions to find DS {avg_exp_to_find_min/tt_g:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc_mds_l = []\n",
    "acc_mdsi_l = []\n",
    "acc_mvc_l = []\n",
    "acc_arg_max_l = []\n",
    "forward_ids = []\n",
    "\n",
    "tt_g = 1000\n",
    "for i in trange(tt_g):\n",
    "    idx_t = torch.Tensor([[i] for i in range(n)])\n",
    "    x = torch.Tensor([[1.]]*n)\n",
    "    x = torch.stack([idx_t, x], dim=1)\n",
    "    g = create_graph(n, p)\n",
    "    edge_list = [(int(a), int(b)) for a, b in g.T]\n",
    "    g_n = nx.from_edgelist(edge_list)\n",
    "    g_n.x = x\n",
    "    g_n.edge_list = g\n",
    "\n",
    "    mvc = milp_solve(deepcopy(g), n)\n",
    "    mds = milp_solve_mds(deepcopy(g), n)\n",
    "\n",
    "    _, maps, best_mdsi = forward(gnn, deepcopy(g_n))\n",
    "    forward_ids.append(best_mdsi)\n",
    "\n",
    "    mvc = torch.FloatTensor([[v in mvc] for v in range(n)])\n",
    "    acc_mvc = ((maps == mvc).sum(dim=1) / y.size(dim=0)).max().item()\n",
    "    mds = torch.FloatTensor([[v in mds] for v in range(n)])\n",
    "    accs = (maps == mds).sum(dim=1) / y.size(dim=0)\n",
    "    arg_max_accs = accs.argmax()\n",
    "    acc_arg_max_l.append(arg_max_accs)\n",
    "    acc_mds = accs.max().item()\n",
    "\n",
    "    mds_i = maps[best_mdsi]\n",
    "    acc_mdsi = (mds == mds_i).sum() / y.size(dim=0)\n",
    "\n",
    "    acc_mds_l.append(acc_mds)\n",
    "    acc_mvc_l.append(acc_mvc)\n",
    "    acc_mdsi_l.append(acc_mdsi)\n",
    "\n",
    "print(f'acc mvc: {sum(acc_mvc_l)/10000}        acc mds: {sum(acc_mds_l)/10000}      acc mds: {sum(acc_mdsi_l)/10000}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum([i == j for i, j in zip(acc_arg_max_l, forward_ids)])/100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(zip(acc_arg_max_l, forward_ids))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
